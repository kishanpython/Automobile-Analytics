{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Complete --->> T_000355.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000356.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000357.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000358.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000359.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000360.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000361.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000362.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000363.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000364.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000365.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000366.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000367.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000368.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000369.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000370.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000371.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000372.CSV\n",
      "**********\n",
      "\n",
      "Reading Complete --->> T_000373.CSV\n",
      "**********\n",
      "\n",
      "Pre-processing file -->  0\n",
      "Pre-processing file -->  1\n",
      "Pre-processing file -->  2\n",
      "Pre-processing file -->  3\n",
      "Pre-processing file -->  4\n",
      "Pre-processing file -->  5\n",
      "Pre-processing file -->  6\n",
      "Pre-processing file -->  7\n",
      "Pre-processing file -->  8\n",
      "Pre-processing file -->  9\n",
      "Pre-processing file -->  10\n",
      "Pre-processing file -->  11\n",
      "Pre-processing file -->  12\n",
      "Pre-processing file -->  13\n",
      "Pre-processing file -->  14\n",
      "Pre-processing file -->  15\n",
      "Pre-processing file -->  16\n",
      "Pre-processing file -->  17\n",
      "Pre-processing file -->  18\n",
      "\n",
      "Data conversion for file --> 0 <--started...\n",
      "\n",
      "Data conversion completed for file --> 0\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 1 <--started...\n",
      "\n",
      "Data conversion completed for file --> 1\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 2 <--started...\n",
      "\n",
      "Data conversion completed for file --> 2\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 3 <--started...\n",
      "\n",
      "Data conversion completed for file --> 3\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 4 <--started...\n",
      "\n",
      "Data conversion completed for file --> 4\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 5 <--started...\n",
      "\n",
      "Data conversion completed for file --> 5\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 6 <--started...\n",
      "\n",
      "Data conversion completed for file --> 6\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 7 <--started...\n",
      "\n",
      "Data conversion completed for file --> 7\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 8 <--started...\n",
      "\n",
      "Data conversion completed for file --> 8\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 9 <--started...\n",
      "\n",
      "Data conversion completed for file --> 9\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 10 <--started...\n",
      "\n",
      "Data conversion completed for file --> 10\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 11 <--started...\n",
      "\n",
      "Data conversion completed for file --> 11\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 12 <--started...\n",
      "\n",
      "Data conversion completed for file --> 12\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 13 <--started...\n",
      "\n",
      "Data conversion completed for file --> 13\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 14 <--started...\n",
      "\n",
      "Data conversion completed for file --> 14\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 15 <--started...\n",
      "\n",
      "Data conversion completed for file --> 15\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 16 <--started...\n",
      "\n",
      "Data conversion completed for file --> 16\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 17 <--started...\n",
      "\n",
      "Data conversion completed for file --> 17\n",
      "#############################\n",
      "\n",
      "\n",
      "Data conversion for file --> 18 <--started...\n",
      "\n",
      "Data conversion completed for file --> 18\n",
      "#############################\n",
      "\n",
      "Data of the file data_preprocessed/T_000355.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000356.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000357.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000358.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000359.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000360.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000361.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000362.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000363.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000364.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000365.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000366.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000367.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000368.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000369.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000370.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000371.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000372.xlsx saved successfully\n",
      "\n",
      "Data of the file data_preprocessed/T_000373.xlsx saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import all neccessary libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# giving cols name to each data and features\n",
    "name=['Date','Latitude', 'Longitude', 'Altitude', 'RPM',\n",
    "        'Driver Demand Torque (%)', 'Engine Load (%)', 'Engine Torque Mode', 'TPS (%)',\n",
    "        'Percent Load Curret Speed', 'Fuel Rate (L-Hr)', 'Vehicle Speed',\n",
    "        'Inj Q Cur (mg-st)', 'Inj Q Tor (mg-st)', 'Boost Pressure (mBar)',\n",
    "        'Atmospheric Pressure (mBar)', 'Coolant Temperature (*C)',\n",
    "        'Oil Temperature (*C)', 'Boost Temperature (*C)', 'Oil Pressure (mBar)',\n",
    "        'Battery Voltage (V)', 'Cam Speed (rpm)', 'Rail Pressure (mBar)',\n",
    "        'Rail Pressure set (mBar)', 'MU PWM (%)', 'MU Vol (mm3-s)',\n",
    "        'Torque Rat', 'Torque (Nm)', 'TQ Limit Set', 'Main Injection (mg-st)',\n",
    "        'Pilot Injection (mg-st)', 'Pos 2 Injector (mg-st)', 'EGR Prop (%)',\n",
    "        'EGR Pos D (%)', 'EGR Pos A (%)', 'Clutch Switch', 'Brake Switch',\n",
    "        'Engine Grad (rpm)', 'param1', 'param2','col_no'\n",
    "]\n",
    "\n",
    "\n",
    "# Data Reader from folder\n",
    "def data_reader():\n",
    "    # iterate over all the '.csv' files kept in the directory\n",
    "    for file_name in glob.glob(directoryPath+'*.csv'):\n",
    "        # read the csv file\n",
    "        data_csv = pd.read_csv(file_name,sep = ',',names=name, index_col=0)\n",
    "        # reset the index\n",
    "        data_csv.reset_index(inplace=True)\n",
    "        # store them into the read_data_stg list\n",
    "        read_data_stg.append(data_csv)\n",
    "        print(f\"Reading Complete --->> {file_name}\" )\n",
    "        print(\"*\"*10)\n",
    "        print()\n",
    "    return read_data_stg\n",
    "\n",
    "# date finder from csv file\n",
    "def date_time_sep(df):\n",
    "    # to find the start and end date\n",
    "    # search term\n",
    "    search_term = ['START', 'END']\n",
    "    # value stg\n",
    "    ans_ = []\n",
    "    # iterate over all the search term to find the value\n",
    "    for ser in search_term:\n",
    "        # checking the rows that contain the search term \n",
    "        check = df[df['Date'].str.contains(ser)]\n",
    "        # resetingtthe index of found row\n",
    "        check.reset_index(inplace=True)\n",
    "        # finding the value of date from (EX:- 'START DATE:040521') after colon\n",
    "        val_of_date = check['Date'][0].split(': ')[1]\n",
    "        # making them into appropriate form  --> 04-05-21\n",
    "        date_conv = val_of_date[0:2]+'-' + val_of_date[2:4] + '-' + val_of_date[4:]\n",
    "        final_date = datetime.strptime(date_conv, '%d-%m-%y').date()\n",
    "        # finally converting into year\n",
    "        val = final_date.strftime(\"%d-%m-%Y\")\n",
    "        # saving the data\n",
    "        ans_.append(val)\n",
    "    return ans_[0]\n",
    "\n",
    "# RPM value convertor\n",
    "def rpm_cal(n, muliplier, offset):\n",
    "    # default values of multiplier\n",
    "    mul = muliplier\n",
    "    # default values of offset\n",
    "    offs = offset\n",
    "    # slicing the LSB and MSB bit and joing them again EX:- 4028 to 2840\n",
    "    val1 = str(n[2:])+str(n[:2])\n",
    "    try:\n",
    "        # finding the hexadecimal to decimal value\n",
    "        # if value in string \n",
    "        final_val = int(val1, 16)\n",
    "    except:\n",
    "        # finding the hexadecimal to decimal value\n",
    "        # if value not in string convert it into int \n",
    "        # and then string\n",
    "        final_val = int(str(int(val1)), 16)\n",
    "    # finally applies the formula for final conversion    \n",
    "    val = (final_val * mul) + offs\n",
    "    return val\n",
    "\n",
    "# Latitude value convertor\n",
    "def lat_convs(num):\n",
    "    # convert it into flot for base checking of 'NaN'\n",
    "    num_chek = float(num)\n",
    "    # cheking of 'NaN' value\n",
    "    if np.isnan(num_chek)==False:\n",
    "        # conversion to string\n",
    "        num = str(num)\n",
    "        # converting from ddmm.mmmmm to dd.dddddd\n",
    "        val_lat = str(num[:2]) + str(float(num[2:])/60)[1:]\n",
    "        return float(val_lat)\n",
    "    else:\n",
    "        # if data is 'NaN' return as_it_is\n",
    "        return num\n",
    "    \n",
    "# longitude conversion\n",
    "def long_convs(num):\n",
    "    # convert it into flot for base checking of 'NaN'\n",
    "    num_chek = float(num)\n",
    "    # cheking of 'NaN' value\n",
    "    if np.isnan(num_chek)==False:\n",
    "        # conversion to string\n",
    "        num = str(num)\n",
    "        # converting from ddmm.mmmmm to dd.dddddd\n",
    "        val_long = str(num[:3]) + str(float(num[3:])/60)[1:]\n",
    "        return float(val_long)\n",
    "    else:\n",
    "        # if data is 'NaN' return as_it_is\n",
    "        return num\n",
    "\n",
    "# conversion for fuel rate columns\n",
    "def convSingleCol(n, muliplier, offset):\n",
    "    \n",
    "    # default values of multiplier\n",
    "    mul = muliplier\n",
    "    # default values of offset\n",
    "    offs = offset\n",
    "    \n",
    "    # taking LSB and MSB bits\n",
    "    val1 = n[:2]\n",
    "    val2 = n[2:]\n",
    "    \n",
    "    try:\n",
    "        # converting the MSB and LSB bits seprately\n",
    "        hex_dec1 = int(val1, 16)\n",
    "        hex_dec2 = int(val2, 16)\n",
    "        # then joing them \n",
    "        final_val = hex_dec1 + hex_dec2\n",
    "    except:\n",
    "        # converting the MSB and LSB bits seprately\n",
    "        hex_dec1 = int(str(int(val1)), 16)\n",
    "        hex_dec2 = int(str(int(val2)), 16)\n",
    "        # then joing them \n",
    "        final_val = hex_dec1 + hex_dec2\n",
    "    # finally applies the formula for final conversion    \n",
    "    val = (final_val * mul) + offs\n",
    "    return val\n",
    "\n",
    "\n",
    "# base function for conversion\n",
    "def ConvHexToDec(n, muliplier, offset):\n",
    "    # default values of multiplier\n",
    "    mul = muliplier\n",
    "    # default values of offset\n",
    "    offs = offset\n",
    "    \n",
    "    try:\n",
    "        # hex to dec\n",
    "        hex_dec = int(n, 16)\n",
    "    except:\n",
    "        # hex to dec\n",
    "        hex_dec = int(str(int(n)), 16)\n",
    "    # final value    \n",
    "    val = (hex_dec * mul) + offs\n",
    "    return val\n",
    "\n",
    "# Pre-processing of the data to remove cols and null values\n",
    "def pre_processing_data_and_date_finder(data_file):\n",
    "    # data storage\n",
    "    pre_processed_data_stg = []\n",
    "    date_stg = []\n",
    "    flag=0\n",
    "    \n",
    "    # loop over all the df one by one\n",
    "    for dfitem in data_file:\n",
    "        print(\"Pre-processing file --> \",flag)\n",
    "        # calculate the start and end date\n",
    "        val = date_time_sep(dfitem)\n",
    "        # store it\n",
    "        date_stg.append(val)\n",
    "        # drop these unwanted cols\n",
    "        dfitem.drop(['Date', 'col_no'], axis=1,inplace=True)\n",
    "        # remove those rows which contain more than 5 null values\n",
    "        # we can change as per our need\n",
    "        # 3 null possible due to lat,lon, and altitude val\n",
    "        dfitem = dfitem[dfitem.isnull().sum(axis=1) < 5]\n",
    "        # storing the value of dataframe\n",
    "        pre_processed_data_stg.append(dfitem)\n",
    "        flag = flag+1\n",
    "    return pre_processed_data_stg,date_stg\n",
    "\n",
    "\n",
    "# base function to run for all above functions\n",
    "def data_conversion_from_pre_processed_data(pre_process_data,date_stg):\n",
    "    # stg area\n",
    "    final_data = []\n",
    "    # flag\n",
    "    flag_date_indx=0\n",
    "    # cheker cols\n",
    "    diff_appr_list = ['RPM','Fuel Rate (L-Hr)']\n",
    "    \n",
    "    # now apply data conversion on pre_processed_data\n",
    "    for df in pre_process_data:\n",
    "        print(f\"\\nData conversion for file --> {flag_date_indx} <--started...\")\n",
    "        print()\n",
    "        # new dataframe creation\n",
    "        new_df = pd.DataFrame(columns=name[:-1])\n",
    "        # latitude values\n",
    "        new_df['Latitude'] = df['Latitude'].apply(lat_convs)\n",
    "        # longitude vals\n",
    "        new_df['Longitude'] = df['Longitude'].apply(long_convs)\n",
    "        # altitude vals\n",
    "        new_df['Altitude'] = df['Altitude']\n",
    "        # date vals\n",
    "        new_df['Date'] = date_stg[flag_date_indx]\n",
    "        \n",
    "        # loop over all the values and for conversion\n",
    "        for indx in range(len(all_col_names)):\n",
    "            # stg of all the col name\n",
    "            item = all_col_names[indx]\n",
    "            \n",
    "            # items other than base cols name\n",
    "            if item not in diff_appr_list:\n",
    "                # base item conversion\n",
    "                new_df[item] = df[item].apply(ConvHexToDec, args=(multiplier_list[indx], offset[indx]))\n",
    "                # cheking of cols <-and-> it's multipliers and offset\n",
    "                #print(f\"------> {item} <-multiplier_value-> {multiplier_list[indx]} <-offset_value-> {offset[indx]}\")\n",
    "                #print(\"*\"*50)\n",
    "                #print()\n",
    "                \n",
    "            # fuel cols conversion\n",
    "            elif item=='Fuel Rate (L-Hr)':\n",
    "                new_df[item] = df[item].apply(convSingleCol, args=(multiplier_list[indx], offset[indx]))\n",
    "                # cheking of cols <-and-> it's multipliers and offset\n",
    "                #print(f\"------> {item} <-multiplier_value-> {multiplier_list[indx]} <-offset_value-> {offset[indx]}\")\n",
    "                #print(\"*\"*50)\n",
    "                #print()\n",
    "                \n",
    "            # other items conversion\n",
    "            else:\n",
    "                new_df[item] = df[item].apply(rpm_cal, args=(multiplier_list[indx], offset[indx]))\n",
    "                #print(f\"------> {item} <-multiplier_value-> {multiplier_list[indx]} <-offset_value-> {offset[indx]}\")\n",
    "        # param cols\n",
    "        new_df['param1'] = df['param1']\n",
    "        new_df['param2'] = df['param2']\n",
    "        # final dataframe stg\n",
    "        final_data.append(new_df)\n",
    "        \n",
    "        print(f\"Data conversion completed for file --> {flag_date_indx}\")\n",
    "        flag_date_indx+=1\n",
    "        print(\"#############################\")\n",
    "        print()\n",
    "    return final_data\n",
    "\n",
    "def saving_data_to_excel(data):\n",
    "    file_names = ['T_000355.xlsx','T_000356.xlsx', 'T_000357.xlsx', 'T_000358.xlsx', 'T_000359.xlsx', \n",
    "                 'T_000360.xlsx', 'T_000361.xlsx', 'T_000362.xlsx', 'T_000363.xlsx', 'T_000364.xlsx', \n",
    "                 'T_000365.xlsx', 'T_000366.xlsx', 'T_000367.xlsx', 'T_000368.xlsx', 'T_000369.xlsx', \n",
    "                 'T_000370.xlsx', 'T_000371.xlsx', 'T_000372.xlsx', 'T_000373.xlsx']\n",
    "\n",
    "    for indx in range(len(data)):\n",
    "        file_name = 'data_preprocessed/'+ str(file_names[indx])\n",
    "        data[indx].to_excel(file_name,index=False)\n",
    "        print(f'Data of the file {file_name} saved successfully')\n",
    "        print()\n",
    "    return 0\n",
    "    \n",
    "\n",
    "# pipeline the data preprocessing steps\n",
    "if __name__ == \"__main__\":\n",
    "    # mention the directory from where to read all csv file\n",
    "    directoryPath = ''\n",
    "    # storage of all csv files using glob\n",
    "    read_data_stg = []\n",
    "    \n",
    "    # read_csv_file_data from the above mentioned directory path\n",
    "    read_data = data_reader()\n",
    "    \n",
    "    # pre-processed_data \n",
    "    pre_process_data,date_stg = pre_processing_data_and_date_finder(read_data)\n",
    "    \n",
    "    # and perform conversion operations\n",
    "    all_data_file = data_conversion_from_pre_processed_data(pre_process_data,date_stg)\n",
    "    \n",
    "    # final data saving to excel\n",
    "    saving_data_to_excel(all_data_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
